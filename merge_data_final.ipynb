{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fusion de Données : TDMS (Groupe Variable) + Xsens\n",
                "\n",
                "Ce notebook fusionne les données d'un groupe TDMS spécifique avec les données Xsens.\n",
                "**Stratégie :**\n",
                "- **Base de Temps (Master)** : Xsens (Timestamp UTC).\n",
                "- **TDMS** : Interpolé sur les temps Xsens.\n",
                "- **Rapport** : Affiche les fréquences, durées et pertes de données."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from nptdms import TdmsFile\n",
                "from datetime import datetime, timedelta\n",
                "import os\n",
                "from scipy.interpolate import interp1d\n",
                "import re\n",
                "\n",
                "# ================= PARAMÈTRES =================\n",
                "TDMS_PATH = r'Sync/TestSyncGPSok.tdms'\n",
                "TXT_PATH = r'Sync/TestSyncGPSok_P2.txt'\n",
                "TARGET_GROUP = 'P2'\n",
                "OUTPUT_CSV = 'Merged_Data.csv'\n",
                "# =============================================="
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_xsens(path):\n",
                "    print(f\"--- Chargement Xsens : {path} ---\")\n",
                "    h_idx = None\n",
                "    try:\n",
                "        with open(path, 'r', errors='ignore') as f:\n",
                "            for i, l in enumerate(f):\n",
                "                if l.strip().startswith('PacketCounter'): h_idx=i; break\n",
                "        if h_idx is None:\n",
                "             with open(path, 'r', errors='ignore') as f:\n",
                "                for i, l in enumerate(f): \n",
                "                    if 'UTC_Year' in l: h_idx=i; break\n",
                "        if h_idx is None: raise ValueError(\"Header introuvable\")\n",
                "        \n",
                "        try: df = pd.read_csv(path, sep='\\t', header=h_idx)\n",
                "        except: df = pd.read_csv(path, sep=r'\\s+', header=h_idx)\n",
                "        \n",
                "        df.columns = df.columns.str.strip()\n",
                "        \n",
                "        # --- FREQUENCE AVANT NETTOYAGE ---\n",
                "        len_raw = len(df)\n",
                "        print(f\"   [Info] Lignes brutes : {len_raw}\")\n",
                "\n",
                "        # --- FIX: Suppression des lignes sans données (Ghost packets) ---\n",
                "        check_cols = [c for c in ['Acc_X', 'FreeAcc_E', 'Gyr_X'] if c in df.columns]\n",
                "        if check_cols:\n",
                "            len_before = len(df)\n",
                "            df.dropna(subset=check_cols, how='all', inplace=True)\n",
                "            dropped = len_before - len(df)\n",
                "            if dropped > 0:\n",
                "                print(f\"   [Info] {dropped} lignes vides supprimees (Ghost Packets).\")\n",
                "        \n",
                "        req = ['UTC_Year', 'UTC_Month', 'UTC_Day', 'UTC_Hour', 'UTC_Minute', 'UTC_Second', 'UTC_Nano']\n",
                "        if set(req).issubset(df.columns):\n",
                "            df.dropna(subset=req, inplace=True)\n",
                "            ts = pd.to_datetime(df[req[:-1]].astype(int).rename(columns={'UTC_Year':'year','UTC_Month':'month','UTC_Day':'day','UTC_Hour':'hour','UTC_Minute':'minute','UTC_Second':'second'}))\n",
                "            df['TS_UTC'] = ts + pd.to_timedelta(df['UTC_Nano'], unit='ns')\n",
                "            df.drop(columns=req, inplace=True)\n",
                "            df.sort_values('TS_UTC', inplace=True)\n",
                "            df.drop_duplicates(subset=['TS_UTC'], inplace=True)\n",
                "            \n",
                "            # Calcul Fréquence RÉELLE APRES NETTOYAGE\n",
                "            if len(df) > 1:\n",
                "                dt = np.diff(df['TS_UTC'].values.astype(float)) / 1e9\n",
                "                freq_real = 1.0 / np.mean(dt)\n",
                "                print(f\"   [RESULTAT] Fréquence calculée APRES nettoyage : {freq_real:.2f} Hz\")\n",
                "\n",
                "            print(f\"Xsens chargé : {len(df)} lignes valides.\")\n",
                "            return df\n",
                "        else: raise ValueError(\"Colonnes UTC manquantes\")\n",
                "    except Exception as e: print(f\"Erreur Xsens: {e}\"); return pd.DataFrame()\n",
                "\n",
                "df_xsens = load_xsens(TXT_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_custom_date(val):\n",
                "    try: return pd.to_datetime(val, dayfirst=True)\n",
                "    except:\n",
                "        try: return pd.to_datetime(str(val).replace(',', '.'), dayfirst=True)\n",
                "        except: return np.nan\n",
                "\n",
                "def load_tdms_group(path, group_name):\n",
                "    print(f\"\\n--- Chargement TDMS Group '{group_name}' ---\")\n",
                "    try:\n",
                "        tdms = TdmsFile.read(path)\n",
                "        found = False; df = pd.DataFrame()\n",
                "        for g in tdms.groups():\n",
                "            if g.name == group_name:\n",
                "                data = {}; \n",
                "                for c in g.channels(): data[c.name] = c[:]\n",
                "                if not data: return pd.DataFrame()\n",
                "                l_min = min(len(v) for v in data.values())\n",
                "                data = {k: v[:l_min] for k,v in data.items()}\n",
                "                df = pd.DataFrame(data); found = True; break\n",
                "        if not found: print(\"Groupe non trouvé\"); return pd.DataFrame()\n",
                "            \n",
                "        ts_col = None; ts_series = None\n",
                "        candidates = [c for c in df.columns if 'Time' in c or 'Date' in c] or df.columns.tolist()\n",
                "        for col in candidates:\n",
                "            sample = df[col].iloc[0]\n",
                "            if isinstance(sample, (int, float)) and 3e9 < sample < 4e9:\n",
                "                print(f\"Timestamp (Num) sur {col}\")\n",
                "                ts_series = pd.to_datetime(df[col], unit='s', origin=pd.Timestamp('1904-01-01')); ts_col = col; break\n",
                "            if isinstance(sample, str) and ('/' in sample or ':' in sample):\n",
                "                 try: \n",
                "                     if parse_custom_date(sample) is not pd.NaT:\n",
                "                         print(f\"Timestamp (Txt) sur {col}\")\n",
                "                         ts_series = df[col].apply(lambda x: parse_custom_date(x) if isinstance(x,str) else x); ts_col = col; break\n",
                "                 except: pass\n",
                "        if ts_series is not None: df['TDMS_Timestamp'] = ts_series\n",
                "        else: print(\"Pas de timestamp TDMS\"); return pd.DataFrame()\n",
                "        df.set_index('TDMS_Timestamp', inplace=True)\n",
                "        df.columns = [f\"TDMS_{c}\" for c in df.columns]\n",
                "        print(f\"TDMS chargé : {len(df)} lignes.\")\n",
                "        return df\n",
                "    except Exception as e: print(f\"Err TDMS: {e}\"); return pd.DataFrame()\n",
                "\n",
                "df_tdms = load_tdms_group(TDMS_PATH, TARGET_GROUP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Fusion, Analyse et Rapport\n",
                "if not df_xsens.empty and not df_tdms.empty:\n",
                "    print(\"\\n================ RAPPORT DE FUSION ================\")\n",
                "    \n",
                "    # Stats avant fusion\n",
                "    start_xs, end_xs = df_xsens['TS_UTC'].min(), df_xsens['TS_UTC'].max()\n",
                "    start_td, end_td = df_tdms.index.min(), df_tdms.index.max()\n",
                "    \n",
                "    print(f\"1. FICHIERS BRUTS (Avant tout traitement)\")\n",
                "    print(f\"   Xsens: {len(df_xsens)} lignes | {start_xs} -> {end_xs}\")\n",
                "    print(f\"   TDMS : {len(df_tdms)} lignes | {start_td} -> {end_td}\")\n",
                "    \n",
                "    # Intervalle commun\n",
                "    t_start_fused = max(start_xs, start_td)\n",
                "    t_end_fused = min(end_xs, end_td)\n",
                "    dur_fused = (t_end_fused - t_start_fused).total_seconds()\n",
                "    \n",
                "    # Vues temporaires zone commune\n",
                "    view_xs = df_xsens[(df_xsens['TS_UTC'] >= t_start_fused) & (df_xsens['TS_UTC'] <= t_end_fused)]\n",
                "    view_td = df_tdms[(df_tdms.index >= t_start_fused) & (df_tdms.index <= t_end_fused)]\n",
                "    \n",
                "    nb_points_xs = len(view_xs)\n",
                "    nb_points_td = len(view_td)\n",
                "    \n",
                "    # Calcul des fréquences réelles\n",
                "    freq_xs = 0; freq_td = 0\n",
                "    if nb_points_xs > 1:\n",
                "         dt_xs = np.diff(view_xs['TS_UTC'].values.astype(float)) / 1e9\n",
                "         freq_xs = 1.0 / np.mean(dt_xs)\n",
                "    if nb_points_td > 1:\n",
                "         dt_td = np.diff(view_td.index.values.astype(float)) / 1e9\n",
                "         freq_td = 1.0 / np.mean(dt_td)\n",
                "    \n",
                "    print(f\"\\n2. ANALYSE ZONE COMMUNE ({dur_fused:.2f} s)\")\n",
                "    print(f\"   Intervalle : {t_start_fused} -> {t_end_fused}\")\n",
                "    print(f\"   Données sources DISPONIBLES (Avant fusion/interpolation) :\")\n",
                "    print(f\"     - Xsens : {nb_points_xs} points (Fréq: {freq_xs:.2f} Hz)\")\n",
                "    print(f\"     - TDMS  : {nb_points_td} points (Fréq: {freq_td:.2f} Hz)\")\n",
                "    \n",
                "    # ANALYSE ALIGNEMENT TEMPOREL (Jitter)\n",
                "    # Si les nombres sont identiques, on regarde si les horloges sont synchrones ou juste meme fréquence\n",
                "    if nb_points_xs == nb_points_td and nb_points_xs > 0:\n",
                "        # Calcul du décalage moyen point à point\n",
                "        # On suppose qu'ils sont appariés 1-1 vu qu'ils ont le meme count dans la meme fenêtre\n",
                "        t_xs = view_xs['TS_UTC'].values.astype(float)\n",
                "        t_td = view_td.index.values.astype(float)\n",
                "        diffs = (t_xs - t_td) / 1e9 # en secondes\n",
                "        mean_diff = np.mean(np.abs(diffs))\n",
                "        max_diff = np.max(np.abs(diffs))\n",
                "        \n",
                "        print(f\"   => TEST ALIGNEMENT (Jitter) :\")\n",
                "        print(f\"      Décalage moyen Timestamp : {mean_diff*1000:.4f} ms\")\n",
                "        print(f\"      Décalage MAX Timestamp   : {max_diff*1000:.4f} ms\")\n",
                "        if mean_diff < 0.0001:\n",
                "            print(\"      -> CONCLUSION : ALIGNEMENT PARFAIT (Données identiques).\")\n",
                "        else:\n",
                "            print(\"      -> CONCLUSION : Fréquences identiques mais décalage temporel (Jitter/Phase).\")\n",
                "            print(\"         L'interpolation est NÉCESSAIRE pour recaler les valeurs TDMS sur les instants Xsens exacts.\")\n",
                "            \n",
                "    \n",
                "    # Fusion\n",
                "    df_merged = view_xs.copy()\n",
                "    df_merged.set_index('TS_UTC', inplace=True)\n",
                "    \n",
                "    # Interpolation TDMS\n",
                "    t_slave = df_tdms.index.values.astype(float)\n",
                "    t_master = df_merged.index.values.astype(float)\n",
                "    \n",
                "    for col in df_tdms.columns:\n",
                "        vals = df_tdms[col].values\n",
                "        f = interp1d(t_slave, vals, kind='linear', bounds_error=False, fill_value=np.nan)\n",
                "        df_merged[col] = f(t_master)\n",
                "        \n",
                "    # Nettoyage colonnes vides\n",
                "    df_merged.dropna(axis=1, how='all', inplace=True)\n",
                "    \n",
                "    print(f\"\\n3. RÉSULTAT FINAL (Après Interpolation)\")\n",
                "    print(f\"   Lignes générées : {len(df_merged)}\")\n",
                "    print(f\"========================================================\")\n",
                "    \n",
                "    print(df_merged.head())\n",
                "    # FIX: Export avec format de date incluant les millisecondes\n",
                "    df_merged.to_csv(OUTPUT_CSV, date_format='%d/%m/%Y %H:%M:%S.%f')\n",
                "    print(f\"\\nFichier CSV sauvegardé : {OUTPUT_CSV}\")\n",
                "else:\n",
                "    print(\"Erreur données manquantes.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}