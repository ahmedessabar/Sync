{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analyse des Essais Invalidés (Reset Edges_RoueAR)\n",
                "\n",
                "**Objectif** : \n",
                "1. Détecter le reset (faux départ) dans TDMS.\n",
                "2. Comparer les durées (Xsens vs TDMS Valide).\n",
                "3. **Afficher les Start Times** pour synchro.\n",
                "\n",
                "**Fichiers Cibles** : `Moto_Chicane_mouille_80`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from nptdms import TdmsFile\n",
                "import matplotlib.pyplot as plt\n",
                "from datetime import datetime, timedelta\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# Chemins ou Fichiers\n",
                "TDMS_PATH = r'Moto_Chicane_mouille_80.tdms'\n",
                "TXT_PATH = r'Moto_Chicane_mouille_80_P1.txt'\n",
                "GROUP_NAME = 'P1'\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CHARGEMENT XSENS ---\n",
                "def load_xsens(path):\n",
                "    print(f\"--- Chargement Xsens : {path} ---\")\n",
                "    h_idx = None\n",
                "    try:\n",
                "        with open(path, 'r', errors='ignore') as f:\n",
                "            for i, l in enumerate(f):\n",
                "                if l.strip().startswith('PacketCounter'): h_idx=i; break\n",
                "        if h_idx is None:\n",
                "             with open(path, 'r', errors='ignore') as f:\n",
                "                for i, l in enumerate(f): \n",
                "                    if 'UTC_Year' in l: h_idx=i; break\n",
                "        if h_idx is None: raise ValueError(\"Header introuvable\")\n",
                "        \n",
                "        try: df = pd.read_csv(path, sep='\\t', header=h_idx)\n",
                "        except: df = pd.read_csv(path, sep=r'\\s+', header=h_idx)\n",
                "        \n",
                "        df.columns = df.columns.str.strip()\n",
                "        \n",
                "        # FIX Ghost Packets\n",
                "        check_cols = [c for c in ['Acc_X', 'FreeAcc_E', 'Gyr_X'] if c in df.columns]\n",
                "        if check_cols:\n",
                "            df.dropna(subset=check_cols, how='all', inplace=True)\n",
                "        \n",
                "        req = ['UTC_Year', 'UTC_Month', 'UTC_Day', 'UTC_Hour', 'UTC_Minute', 'UTC_Second', 'UTC_Nano']\n",
                "        if set(req).issubset(df.columns):\n",
                "            df.dropna(subset=req, inplace=True)\n",
                "            ts = pd.to_datetime(df[req[:-1]].astype(int).rename(columns={'UTC_Year':'year','UTC_Month':'month','UTC_Day':'day','UTC_Hour':'hour','UTC_Minute':'minute','UTC_Second':'second'}))\n",
                "            df['TS_UTC'] = ts + pd.to_timedelta(df['UTC_Nano'], unit='ns')\n",
                "            df.drop(columns=req, inplace=True)\n",
                "            df.sort_values('TS_UTC', inplace=True)\n",
                "            df.drop_duplicates(subset=['TS_UTC'], inplace=True)\n",
                "            return df\n",
                "        else: raise ValueError(\"Colonnes UTC manquantes\")\n",
                "    except Exception as e: print(f\"Erreur Xsens: {e}\"); return pd.DataFrame()\n",
                "\n",
                "df_xs = load_xsens(TXT_PATH)\n",
                "xsens_start = pd.NaT\n",
                "\n",
                "if not df_xs.empty:\n",
                "    xsens_start = df_xs['TS_UTC'].min()\n",
                "else:\n",
                "    print(\"[XSENS] Erreur chargement.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ANALYSE TDMS & SYNTHESE\n",
                "reset_index = None\n",
                "tdms_start_time = None\n",
                "tdms_fs = 400.0\n",
                "\n",
                "try:\n",
                "    tdms = TdmsFile.read(TDMS_PATH)\n",
                "    group = tdms[GROUP_NAME]\n",
                "    \n",
                "    # 1. Recherche Timestamp Metadata (Méthode Specifique Channel Edges_RoueAR)\n",
                "    # \"start_time = pd.to_datetime(channel.properties.get('wf_start_time')).tz_localize(None)\"\n",
                "    \n",
                "    if 'Edges_RoueAR' in group:\n",
                "        chan = group['Edges_RoueAR']\n",
                "        if 'wf_start_time' in chan.properties:\n",
                "            raw_time = chan.properties['wf_start_time']\n",
                "            tdms_start_time = pd.to_datetime(raw_time).tz_localize(None)\n",
                "            print(f\"  -> Trouvé (Channel 'Edges_RoueAR') : {tdms_start_time}\")\n",
                "            \n",
                "    # Fallback Root si pas trouvé dans le channel\n",
                "    if not tdms_start_time and 'wf_start_time' in tdms.properties:\n",
                "         v = tdms.properties['wf_start_time']\n",
                "         tdms_start_time = pd.to_datetime(v).tz_localize(None)\n",
                "         print(f\"  -> Trouvé (Root) : {tdms_start_time}\")\n",
                "\n",
                "    \n",
                "    # 2. Data & Reset\n",
                "    chan_edges = group['Edges_RoueAR']\n",
                "    edges_data = chan_edges[:]\n",
                "    \n",
                "    def detect_reset_index(data, threshold=-100):\n",
                "        diffs = np.diff(data)\n",
                "        resets = np.where(diffs < threshold)[0]\n",
                "        if len(resets) > 0: return resets[0] + 1\n",
                "        return None\n",
                "\n",
                "    reset_index = detect_reset_index(edges_data)\n",
                "    \n",
                "    # --- AFFICHAGE RESULTATS ---\n",
                "    print(\"\\n================ SYNTHESE ================\")\n",
                "    print(f\"1. XSENS START Time       : {xsens_start}\")\n",
                "    \n",
                "    if tdms_start_time:\n",
                "        print(f\"2. TDMS START Time (Meta) : {tdms_start_time}\")\n",
                "    else:\n",
                "        print(f\"2. TDMS START Time (Meta) : [NON TROUVE]\")\n",
                "        \n",
                "    print(f\"\\n3. DETECTION RESET\")\n",
                "    if reset_index:\n",
                "        print(f\"   -> Reset détecté à l'index : {reset_index}\")\n",
                "        dur_invalid = reset_index / tdms_fs\n",
                "        print(f\"   -> Durée partie invalide   : {dur_invalid:.2f} s\")\n",
                "        \n",
                "        if tdms_start_time:\n",
                "             tdms_start_valid = tdms_start_time + timedelta(seconds=dur_invalid)\n",
                "             print(f\"   -> TDMS Start Partie 2     : {tdms_start_valid} (Calculé)\")\n",
                "             \n",
                "             delta = xsens_start - tdms_start_valid\n",
                "             print(f\"   -> DECALAGE (Xsens - Valid): {delta.total_seconds():.4f} s\")\n",
                "    else:\n",
                "        print(\"   -> Aucun reset détecté.\")\n",
                "        \n",
                "    print(f\"\\n4. COMPARAISON TAILLES\")\n",
                "    xsens_count = len(df_xs)\n",
                "    tdms_valid_count = len(edges_data) - (reset_index if reset_index else 0)\n",
                "    print(f\"   Xsens Total : {xsens_count}\")\n",
                "    print(f\"   TDMS Valide : {tdms_valid_count}\")\n",
                "    print(f\"   Difference  : {xsens_count - tdms_valid_count}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Erreur: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}