{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fusion AVANCÉE : TDMS avec Resets (Essais Invalidés)\n",
                "\n",
                "**Version Spéciale v2** : Ignore le timestamp TDMS si un reset est détecté.\n",
                "\n",
                "**Logique** :\n",
                "1. **Detection Reset** : Si trouvé, on considère que le fichier contient une partie invalide + concaténation.\n",
                "2. **Ignore TDMS Start** : Le timestamp du fichier metadata est inutile (car temps d'arrêt inconnu).\n",
                "3. **Forced Sync** : On cale le début de la partie valide sur `Xsens Start + 0.2679s`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from nptdms import TdmsFile\n",
                "from scipy.interpolate import interp1d\n",
                "from datetime import datetime, timedelta\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# --- CONFIGURATION ---\n",
                "f_xsens = r'Moto_Chicane_mouille_80_P1.txt'\n",
                "f_tdms = r'Moto_Chicane_mouille_80.tdms'\n",
                "tdms_group = 'P1'\n",
                "OUTPUT_CSV = 'Merged_Corrupted_Fixed.csv'\n",
                "\n",
                "TDMS_FREQ = 400.0\n",
                "MAGIC_OFFSET = 0.2679 # Seconde"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_xsens(path):\n",
                "    print(f\"--- Chargement Xsens : {path} ---\")\n",
                "    h_idx = None\n",
                "    try:\n",
                "        with open(path, 'r', errors='ignore') as f:\n",
                "            for i, l in enumerate(f):\n",
                "                if l.strip().startswith('PacketCounter'): h_idx=i; break\n",
                "        if h_idx is None:\n",
                "             with open(path, 'r', errors='ignore') as f:\n",
                "                for i, l in enumerate(f): \n",
                "                    if 'UTC_Year' in l: h_idx=i; break\n",
                "        if h_idx is None: raise ValueError(\"Header introuvable\")\n",
                "        \n",
                "        try: df = pd.read_csv(path, sep='\\t', header=h_idx)\n",
                "        except: df = pd.read_csv(path, sep=r'\\s+', header=h_idx)\n",
                "        \n",
                "        df.columns = df.columns.str.strip()\n",
                "        \n",
                "        # FIX Ghost Packets\n",
                "        check_cols = [c for c in ['Acc_X', 'FreeAcc_E', 'Gyr_X'] if c in df.columns]\n",
                "        if check_cols:\n",
                "            df.dropna(subset=check_cols, how='all', inplace=True)\n",
                "        \n",
                "        req = ['UTC_Year', 'UTC_Month', 'UTC_Day', 'UTC_Hour', 'UTC_Minute', 'UTC_Second', 'UTC_Nano']\n",
                "        if set(req).issubset(df.columns):\n",
                "            df.dropna(subset=req, inplace=True)\n",
                "            ts = pd.to_datetime(df[req[:-1]].astype(int).rename(columns={'UTC_Year':'year','UTC_Month':'month','UTC_Day':'day','UTC_Hour':'hour','UTC_Minute':'minute','UTC_Second':'second'}))\n",
                "            df['TS_UTC'] = ts + pd.to_timedelta(df['UTC_Nano'], unit='ns')\n",
                "            df.drop(columns=req, inplace=True)\n",
                "            df.sort_values('TS_UTC', inplace=True)\n",
                "            df.drop_duplicates(subset=['TS_UTC'], inplace=True)\n",
                "            \n",
                "            print(f\"Xsens chargé : {len(df)} lignes.\")\n",
                "            return df\n",
                "        else: raise ValueError(\"Colonnes UTC manquantes\")\n",
                "    except Exception as e: print(f\"Erreur Xsens: {e}\"); return pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_tdms_special(path, group_name, xsens_start_ref=None):\n",
                "    print(f\"\\n--- Chargement TDMS SPECIAL '{group_name}' ---\")\n",
                "    try:\n",
                "        tdms = TdmsFile.read(path)\n",
                "        target_group = None\n",
                "        for g in tdms.groups():\n",
                "            if g.name == group_name: target_group = g; break\n",
                "        if not target_group: print(\"Groupe non trouvé\"); return pd.DataFrame()\n",
                "        \n",
                "        # 1. Données Brutes\n",
                "        data = {}\n",
                "        for c in target_group.channels(): data[c.name] = c[:]\n",
                "        if not data: return pd.DataFrame()\n",
                "        l_min = min(len(v) for v in data.values())\n",
                "        data = {k: v[:l_min] for k,v in data.items()}\n",
                "        df = pd.DataFrame(data)\n",
                "        \n",
                "        base_start_time = None\n",
                "        \n",
                "        # 2. Detection Reset\n",
                "        start_index = 0\n",
                "        reset_detected = False\n",
                "        \n",
                "        if 'Edges_RoueAR' in df.columns:\n",
                "            diffs = np.diff(df['Edges_RoueAR'].values)\n",
                "            resets = np.where(diffs < -100)[0]\n",
                "            if len(resets) > 0:\n",
                "                start_index = resets[0] + 1\n",
                "                reset_detected = True\n",
                "                print(f\"   [SPECIAL] RESET détecté index {start_index}\")\n",
                "                print(\"   -> Mode 'Essai Invalidé' activé.\")\n",
                "                print(\"   -> IGNORAGE Metadata TDMS (concaténation inconnue).\")\n",
                "            else:\n",
                "                print(\"   [Info] Pas de reset détecté. Mode classique.\")\n",
                "\n",
                "        # 3. Stratégie Timestamp\n",
                "        if reset_detected and xsens_start_ref:\n",
                "            # STRATEGIE FORCÉE : On se cale sur Xsens + Offset fix\n",
                "            base_start_time = xsens_start_ref + timedelta(seconds=MAGIC_OFFSET)\n",
                "            print(f\"   [SYNC FORCÉE] TDMS Start = Xsens Start ({xsens_start_ref}) + {MAGIC_OFFSET}s\")\n",
                "            print(f\"                 = {base_start_time}\")\n",
                "            \n",
                "        else:\n",
                "            # Mode Classique (Metadata)\n",
                "            if 'Edges_RoueAR' in target_group:\n",
                "                chan = target_group['Edges_RoueAR']\n",
                "                if 'wf_start_time' in chan.properties:\n",
                "                     base_start_time = pd.to_datetime(chan.properties['wf_start_time']).tz_localize(None)\n",
                "            if not base_start_time and 'wf_start_time' in tdms.properties:\n",
                "                 base_start_time = pd.to_datetime(tdms.properties['wf_start_time']).tz_localize(None)\n",
                "            print(f\"   [Info] Start Time Meta utilisé : {base_start_time}\")\n",
                "        \n",
                "        # 4. Slice Data (Uniquement si Reset)\n",
                "        if start_index > 0:\n",
                "            df = df.iloc[start_index:].copy().reset_index(drop=True)\n",
                "            \n",
                "        # 5. Index Temporel 400Hz\n",
                "        if base_start_time:\n",
                "            time_index = pd.date_range(start=base_start_time, periods=len(df), freq=f'{1000/TDMS_FREQ}ms')\n",
                "            df['TDMS_Timestamp'] = time_index\n",
                "            df.set_index('TDMS_Timestamp', inplace=True)\n",
                "            df.columns = [f\"TDMS_{c}\" for c in df.columns]\n",
                "            print(f\"TDMS chargé : {len(df)} lignes valides.\")\n",
                "            return df\n",
                "        else:\n",
                "            print(\"ERREUR: Pas de Start Time défini !\")\n",
                "            return pd.DataFrame()\n",
                "\n",
                "    except Exception as e: print(f\"Err {e}\"); return pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# FUSION\n",
                "df_xsens = load_xsens(f_xsens)\n",
                "\n",
                "if not df_xsens.empty:\n",
                "    xsens_start = df_xsens['TS_UTC'].min()\n",
                "    # On passe le start time xsens pour qu'il serve de référence\n",
                "    df_tdms = load_tdms_special(f_tdms, tdms_group, xsens_start_ref=xsens_start)\n",
                "\n",
                "    if not df_tdms.empty:\n",
                "        print(\"\\nFusion...\")\n",
                "        t_start = max(df_xsens['TS_UTC'].min(), df_tdms.index.min())\n",
                "        t_end = min(df_xsens['TS_UTC'].max(), df_tdms.index.max())\n",
                "        print(f\"Intervalle Commun : {t_start} -> {t_end}\")\n",
                "        \n",
                "        df_merged = df_xsens[(df_xsens['TS_UTC'] >= t_start) & (df_xsens['TS_UTC'] <= t_end)].copy()\n",
                "        df_merged.set_index('TS_UTC', inplace=True)\n",
                "        \n",
                "        # Interpolation\n",
                "        t_slave = (df_tdms.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1ns') / 1e9\n",
                "        t_master = (df_merged.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1ns') / 1e9\n",
                "        \n",
                "        for col in df_tdms.columns:\n",
                "            f = interp1d(t_slave, df_tdms[col].values, kind='linear', fill_value=\"extrapolate\")\n",
                "            df_merged[col] = f(t_master)\n",
                "            \n",
                "        df_merged.to_csv(OUTPUT_CSV, date_format='%d/%m/%Y %H:%M:%S.%f')\n",
                "        print(f\"Terminé : {OUTPUT_CSV}\")\n",
                "        print(df_merged.head())\n",
                "else:\n",
                "    print(\"Erreur chargement Xsens\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}